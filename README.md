# Large-scale-Vision

- SAM: Segment Anything [[`Paper`]](https://arxiv.org/abs/2304.02643) [[`Dataset`]](https://segment-anything.com/dataset/index.html)
  - SA-1B Dataset:
  Total number of images: 11M
  Total number of masks: 1.1B
  Average masks per image: 100
  Average image resolution: 1500Ã—2250 pixels

- ImageNet: A Large-Scale Hierarchical Image Database [[`Paper`]](https://ieeexplore.ieee.org/abstract/document/5206848) [[`Dataset`]](https://www.image-net.org/download.php)
  - This dataset spans 1000 object classes and contains 1,281,167 training images, 50,000 validation images and 100,000 test images. 

- MVImgNet: A Large-scale Dataset of Multi-view Images [[`Paper`]](https://arxiv.org/abs/2303.06042) [[`Dataset`]](https://gaplab.cuhk.edu.cn/projects/MVImgNet/)
  -  It contains 6.5 million frames from 219,188 videos crossing objects from 238 classes, with rich annotations of object masks, camera parameters, and point clouds. 

- Large Scale Visual Food Recognition [[`Paper`]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10019590) [[`Dataset`]](http://123.57.42.89/FoodProject.html)
  - A new large-scale high-quality food recognition benchmark Food2K, which is the largest food image dataset with 2,000 categories and 1,036,564 images

- LogoDet-3K: A Large-scale Image Dataset for Logo Detection [[`Paper`]](https://dl.acm.org/doi/pdf/10.1145/3466780) [[`Dataset`]](https://github.com/Wangjing1551/LogoDet-3K-Dataset)
  -  A new large-scale logo dataset LogoDet-3K1 with 3,000 classes, 194,261 objects and 158,652 images, which is the largest logo classes with full annotation.

- Objects365: A Large-scale, High-quality Dataset for Object Detection [[`Paper`]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.pdf) [[`Dataset`]](http://www.objects365.org/overview.html)
  - Objects365 is a brand new dataset, designed to spur object detection research with a focus on diverse objects in the Wild.
    365 categories
    2 million images
    30 million bounding boxes

- TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild [[`Paper`]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Matthias_Muller_TrackingNet_A_Large-Scale_ECCV_2018_paper.pdf) [[`Dataset`]](https://tracking-net.org/)
  - A Large-Scale Dataset and Benchmark for Object Tracking in the Wild.Large Scale Dataset > 30K Video Sequences, Object Tracking > 14M Bounding Boxes

---  
## Multimodal
- LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs [[`Paper`]](https://arxiv.org/abs/2111.02114) [[`Dataset`]](https://laion.ai/blog/laion-400-open-dataset/)
  - Number of unique samples 413M
Number with height or width >= 1024 26M
Number with height and width >= 1024 9.6M
Number with height or width >= 512 112M
Number with height and width >= 512 67M
Number with height or width >= 256 268M
Number with height and width >= 256 211M


- Redcaps: Web-curated imagetext data created by the people, for the people  [[`Paper`]](https://arxiv.org/abs/2111.11431) [[`Dataset`]](https://redcaps.xyz/)
  -  12M image-text pairs

- Wukong: A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark [[`Paper`]](https://arxiv.org/abs/2202.06767) [[`Dataset`]](https://wukong-dataset.github.io/wukong-dataset/)
  - A large-scale Chinese VLP dataset with 100 million image-text pairs, covering a wide range of concepts.